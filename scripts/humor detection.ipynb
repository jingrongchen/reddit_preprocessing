{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# import networkx as nx\n",
    "# from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            object\n",
      "summarized     int64\n",
      "text          object\n",
      "root          object\n",
      "length         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "all_posts_df = pd.read_csv('../data/merged_q/all_posts_max_len_10.csv')\n",
    "all_posts_df.head()\n",
    "print(all_posts_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>summarized</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hm5iqwj</td>\n",
       "      <td>r2nmvy</td>\n",
       "      <td>1</td>\n",
       "      <td>Conscious Club is campy in a good way</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hm5kaqv</td>\n",
       "      <td>r2nmvy</td>\n",
       "      <td>0</td>\n",
       "      <td>I like Scary Pockets.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hm5kddu</td>\n",
       "      <td>r2nylj</td>\n",
       "      <td>0</td>\n",
       "      <td>what keeps me calm is my prescription medication</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hm5kig9</td>\n",
       "      <td>r2nylj</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow you're amazingly talented.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hm5kl30</td>\n",
       "      <td>r2npa3</td>\n",
       "      <td>0</td>\n",
       "      <td>Walking in the countryside withan audiobook.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id parent_id  summarized  \\\n",
       "0  hm5iqwj    r2nmvy           1   \n",
       "1  hm5kaqv    r2nmvy           0   \n",
       "2  hm5kddu    r2nylj           0   \n",
       "3  hm5kig9    r2nylj           1   \n",
       "4  hm5kl30    r2npa3           0   \n",
       "\n",
       "                                               text  length  \n",
       "0             Conscious Club is campy in a good way       8  \n",
       "1                             I like Scary Pockets.       5  \n",
       "2  what keeps me calm is my prescription medication       8  \n",
       "3                    Wow you're amazingly talented.       6  \n",
       "4      Walking in the countryside withan audiobook.       7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_replies_df = pd.read_csv('../data/merged_q/all_replies_max_len_10.csv')\n",
    "all_replies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CPU\n",
      "\n",
      "\n",
      "\n",
      "# RAM\n",
      "\n",
      "# GPU\n",
      "\n",
      "# OS\n",
      "Darwin MagicMac 20.6.0 Darwin Kernel Version 20.6.0: Tue Oct 12 18:33:42 PDT 2021; root:xnu-7195.141.8~1/RELEASE_X86_64 x86_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: /proc/cpuinfo: No such file or directory\n",
      "cat: /proc/cpuinfo: No such file or directory\n",
      "cat: /proc/cpuinfo: No such file or directory\n",
      "cat: /proc/meminfo: No such file or directory\n",
      "/bin/sh: lspci: command not found\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from ast import literal_eval\n",
    "\n",
    "def run(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "    print(out.decode('utf-8').strip())\n",
    "\n",
    "print('# CPU')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n",
    "\n",
    "print('# RAM')\n",
    "run('cat /proc/meminfo | egrep \"^MemTotal\"')\n",
    "\n",
    "print('# GPU')\n",
    "run('lspci | grep VGA')\n",
    "\n",
    "print('# OS')\n",
    "run('uname -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 21:54:56.677612: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (Custom>TFBertMainLayer)  multiple             109482240   ['input_19[0][0]',               \n",
      "                                                                  'input_20[0][0]',               \n",
      "                                                                  'input_21[0][0]',               \n",
      "                                                                  'input_22[0][0]',               \n",
      "                                                                  'input_23[0][0]',               \n",
      "                                                                  'input_24[0][0]',               \n",
      "                                                                  'input_25[0][0]',               \n",
      "                                                                  'input_26[0][0]',               \n",
      "                                                                  'input_27[0][0]',               \n",
      "                                                                  'input_28[0][0]',               \n",
      "                                                                  'input_29[0][0]',               \n",
      "                                                                  'input_30[0][0]',               \n",
      "                                                                  'input_31[0][0]',               \n",
      "                                                                  'input_32[0][0]',               \n",
      "                                                                  'input_33[0][0]',               \n",
      "                                                                  'input_34[0][0]',               \n",
      "                                                                  'input_35[0][0]',               \n",
      "                                                                  'input_36[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 768)         0           ['bert[0][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 768)         0           ['bert[1][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 768)         0           ['bert[2][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 768)         0           ['bert[3][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 768)         0           ['bert[4][0]']                   \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 768)         0           ['bert[5][0]']                   \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           24608       ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 32)           24608       ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 32)           24608       ['global_average_pooling1d_8[0][0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 32)           24608       ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 32)           24608       ['global_average_pooling1d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 256)          196864      ['global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 32)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 32)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 32)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 32)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 32)           0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 256)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 8)            264         ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 8)            264         ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 8)            264         ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 8)            264         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 8)            264         ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64)           16448       ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 104)          0           ['dense_16[0][0]',               \n",
      "                                                                  'dense_18[0][0]',               \n",
      "                                                                  'dense_20[0][0]',               \n",
      "                                                                  'dense_22[0][0]',               \n",
      "                                                                  'dense_24[0][0]',               \n",
      "                                                                  'dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 512)          53760       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 512)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 256)          131328      ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            257         ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,005,257\n",
      "Trainable params: 110,005,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"../Colbert/colbert-trained/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.fnet.tokenization_fnet because of the following error (look up to see its traceback):\nNo module named 'sentencepiece'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2776\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/transformers/models/fnet/tokenization_fnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msentencepiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentencepiece'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/3f71ctjx64zgpnygz80qt4bw0000gn/T/ipykernel_31324/1869850204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspearmanr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfloor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2766\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2765\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2767\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2768\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2779\u001b[0m             raise RuntimeError(\n\u001b[1;32m   2780\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2781\u001b[0;31m             ) from e\n\u001b[0m\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.fnet.tokenization_fnet because of the following error (look up to see its traceback):\nNo module named 'sentencepiece'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnchen/opt/anaconda3/envs/SP/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|████████████████████████████| 226k/226k [00:00<00:00, 588kB/s]\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 9.13kB/s]\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 243kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample_count = 1000 # 4000\n",
    "test_count = 1000\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts_df_test=all_posts_df.sample(n=10,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summarized</th>\n",
       "      <th>text</th>\n",
       "      <th>root</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>lmfqjq</td>\n",
       "      <td>0</td>\n",
       "      <td>I can see Mount Fuji outside my window</td>\n",
       "      <td>see</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47982</th>\n",
       "      <td>7or70u</td>\n",
       "      <td>0</td>\n",
       "      <td>Im at home waiting for a robber</td>\n",
       "      <td>be</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>nsp4wk</td>\n",
       "      <td>1</td>\n",
       "      <td>I look back and not one thing went wrong.</td>\n",
       "      <td>look</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34177</th>\n",
       "      <td>a713ot</td>\n",
       "      <td>1</td>\n",
       "      <td>Would love to chat for a distraction!</td>\n",
       "      <td>love</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50478</th>\n",
       "      <td>7b26kv</td>\n",
       "      <td>1</td>\n",
       "      <td>Why even put THAT much effort into a reply?</td>\n",
       "      <td>put</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39368</th>\n",
       "      <td>94rroc</td>\n",
       "      <td>1</td>\n",
       "      <td>I started university last year around October.</td>\n",
       "      <td>start</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51131</th>\n",
       "      <td>77r5f1</td>\n",
       "      <td>0</td>\n",
       "      <td>What’s keeping you up tonight?</td>\n",
       "      <td>keep</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>fxo0ry</td>\n",
       "      <td>0</td>\n",
       "      <td>Trying to stay up cause my cat is sick</td>\n",
       "      <td>try</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25169</th>\n",
       "      <td>d1xlnh</td>\n",
       "      <td>0</td>\n",
       "      <td>So I forgot my cake day</td>\n",
       "      <td>forget</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20567</th>\n",
       "      <td>ekxmb5</td>\n",
       "      <td>1</td>\n",
       "      <td>My ex boyfriend's fuck buddy bought me presents.</td>\n",
       "      <td>buy</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  summarized                                              text  \\\n",
       "5166   lmfqjq           0            I can see Mount Fuji outside my window   \n",
       "47982  7or70u           0                   Im at home waiting for a robber   \n",
       "3447   nsp4wk           1         I look back and not one thing went wrong.   \n",
       "34177  a713ot           1             Would love to chat for a distraction!   \n",
       "50478  7b26kv           1       Why even put THAT much effort into a reply?   \n",
       "39368  94rroc           1    I started university last year around October.   \n",
       "51131  77r5f1           0                    What’s keeping you up tonight?   \n",
       "15174  fxo0ry           0            Trying to stay up cause my cat is sick   \n",
       "25169  d1xlnh           0                           So I forgot my cake day   \n",
       "20567  ekxmb5           1  My ex boyfriend's fuck buddy bought me presents.   \n",
       "\n",
       "         root  length  \n",
       "5166      see       8  \n",
       "47982      be       8  \n",
       "3447     look      10  \n",
       "34177    love       8  \n",
       "50478     put      10  \n",
       "39368   start       8  \n",
       "51131    keep       7  \n",
       "15174     try       9  \n",
       "25169  forget       6  \n",
       "20567     buy      10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['text'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/3f71ctjx64zgpnygz80qt4bw0000gn/T/ipykernel_31324/494422275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# input_categories = list(all_posts_df_test.columns[[2]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_categories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_input_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_posts_df_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mall_posts_df_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mall_posts_df_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_posts_df_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f0/3f71ctjx64zgpnygz80qt4bw0000gn/T/ipykernel_31324/3788998583.py\u001b[0m in \u001b[0;36mcompute_input_arrays\u001b[0;34m(df, columns, tokenizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['text'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# input_categories = list(all_posts_df_test.columns[[2]])\n",
    "input_categories=['text']\n",
    "test_inputs = compute_input_arrays(all_posts_df_test, input_categories, tokenizer)\n",
    "all_posts_df_test['humor']=model.predict(test_inputs)\n",
    "all_posts_df_test['humor'] = all_posts_df_test['humor'].apply(lambda x:True if x>0.7 else False)\n",
    "\n",
    "\n",
    "endtime = datetime.datetime.now()\n",
    "print (endtime - starttime)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f0/3f71ctjx64zgpnygz80qt4bw0000gn/T/ipykernel_31324/768355491.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# input_categories = list(all_posts_df_test.columns[[2]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_categories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_input_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolbert_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcolbert_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcolbert_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_posts_df_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'humor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f0/3f71ctjx64zgpnygz80qt4bw0000gn/T/ipykernel_31324/3788998583.py\u001b[0m in \u001b[0;36mcompute_input_arrays\u001b[0;34m(df, columns, tokenizer)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# sent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SENTENCES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/SP/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "colbert_df = pd.read_csv('../data/matched_q/casual_conv_20160101_20161231.csv')\n",
    "# input_categories = list(all_posts_df_test.columns[[2]])\n",
    "input_categories=['src_text']\n",
    "test_inputs = compute_input_arrays(colbert_df, input_categories, tokenizer)\n",
    "colbert_df['humor']=model.predict(test_inputs)\n",
    "colbert_df['humor'] = all_posts_df_test['humor'].apply(lambda x:True if x>0.7 else False)\n",
    "\n",
    "\n",
    "endtime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_id             object\n",
      "src_type           object\n",
      "src_summarized      int64\n",
      "src_from           object\n",
      "src_text           object\n",
      "src_root           object\n",
      "src_length          int64\n",
      "com_id             object\n",
      "com_summarized      int64\n",
      "com_text           object\n",
      "com_length          int64\n",
      "com_score         float64\n",
      "combined           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "colbert_df = pd.read_csv('../data/matched_q/casual_conv_20160101_20161231.csv')\n",
    "colbert_df=colbert_df.sample(n=10,random_state=1)\n",
    "colbert_df['combined'] =colbert_df['src_text']+' '+colbert_df['com_text']\n",
    "input_categories=['combined']\n",
    "# print(colbert_df)\n",
    "\n",
    "print(colbert_df.dtypes)\n",
    "\n",
    "# test_inputs = compute_input_arrays(colbert_df, input_categories, tokenizer)\n",
    "# for i in tqdm(range(colbert_df.shape[0])):\n",
    "#     colbert_df.iloc[i]['humor']=model.predict(test_inputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_summarized</th>\n",
       "      <th>src_from</th>\n",
       "      <th>src_text</th>\n",
       "      <th>src_root</th>\n",
       "      <th>src_length</th>\n",
       "      <th>com_id</th>\n",
       "      <th>com_summarized</th>\n",
       "      <th>com_text</th>\n",
       "      <th>com_length</th>\n",
       "      <th>com_score</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>dfbm0ii</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>*cricris*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dfbra18</td>\n",
       "      <td>0</td>\n",
       "      <td>I WIN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*cricris* I WIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>dcg0p50</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Me too Tights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dcg14yr</td>\n",
       "      <td>0</td>\n",
       "      <td>Cat Tights</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Me too Tights Cat Tights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>dd1h0nk</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>ALL.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dd1h5xd</td>\n",
       "      <td>1</td>\n",
       "      <td>MISTAKEN.</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL. MISTAKEN.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>dd5f1tz</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Oh, silly Mozilla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>dd5o05g</td>\n",
       "      <td>0</td>\n",
       "      <td>but it was so boring 3xx</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh, silly Mozilla... but it was so boring 3xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>dcchr6y</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Any bright ideas :I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>dcci12p</td>\n",
       "      <td>0</td>\n",
       "      <td>Lamps.</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Any bright ideas :I Lamps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>dckdc2c</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>DAS NOT TROOOOOO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dckdpyt</td>\n",
       "      <td>0</td>\n",
       "      <td>PUH ROOF ITTTTTTT</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DAS NOT TROOOOOO PUH ROOF ITTTTTTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>dcko6if</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Military Tights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dckoa9k</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracks Tights</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Military Tights Barracks Tights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>dcg2dc8</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Stocking Tights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dcg2dwq</td>\n",
       "      <td>0</td>\n",
       "      <td>Garter Tights</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stocking Tights Garter Tights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>dc92bpt</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Ohh goodness.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dc968cv</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeahh.</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ohh goodness. Yeahh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>dc0lvfe</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Ebay Tights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dc0m02i</td>\n",
       "      <td>0</td>\n",
       "      <td>Craigslist Tights</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ebay Tights Craigslist Tights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       src_id src_type  src_summarized src_from              src_text  \\\n",
       "1743  dfbm0ii      com               0  comment             *cricris*   \n",
       "969   dcg0p50      com               0  comment         Me too Tights   \n",
       "1355  dd1h0nk      com               0  comment                  ALL.   \n",
       "2159  dd5f1tz      com               0  comment  Oh, silly Mozilla...   \n",
       "1897  dcchr6y      com               0  comment   Any bright ideas :I   \n",
       "1283  dckdc2c      com               0  comment      DAS NOT TROOOOOO   \n",
       "1009  dcko6if      com               0  comment       Military Tights   \n",
       "982   dcg2dc8      com               0  comment       Stocking Tights   \n",
       "1213  dc92bpt      com               0  comment         Ohh goodness.   \n",
       "484   dc0lvfe      com               0  comment           Ebay Tights   \n",
       "\n",
       "     src_root  src_length   com_id  com_summarized                  com_text  \\\n",
       "1743      NaN           3  dfbra18               0                     I WIN   \n",
       "969       NaN           3  dcg14yr               0                Cat Tights   \n",
       "1355      NaN           2  dd1h5xd               1                 MISTAKEN.   \n",
       "2159      NaN           5  dd5o05g               0  but it was so boring 3xx   \n",
       "1897      NaN           5  dcci12p               0                    Lamps.   \n",
       "1283      NaN           3  dckdpyt               0         PUH ROOF ITTTTTTT   \n",
       "1009      NaN           2  dckoa9k               0           Barracks Tights   \n",
       "982       NaN           2  dcg2dwq               0             Garter Tights   \n",
       "1213      NaN           3  dc968cv               1                    Yeahh.   \n",
       "484       NaN           2  dc0m02i               0         Craigslist Tights   \n",
       "\n",
       "      com_length  com_score                                       combined  \n",
       "1743           2        NaN                                *cricris* I WIN  \n",
       "969            2        NaN                       Me too Tights Cat Tights  \n",
       "1355           2        NaN                                 ALL. MISTAKEN.  \n",
       "2159           6        NaN  Oh, silly Mozilla... but it was so boring 3xx  \n",
       "1897           2        NaN                     Any bright ideas :I Lamps.  \n",
       "1283           3        NaN             DAS NOT TROOOOOO PUH ROOF ITTTTTTT  \n",
       "1009           2        NaN                Military Tights Barracks Tights  \n",
       "982            2        NaN                  Stocking Tights Garter Tights  \n",
       "1213           2        NaN                           Ohh goodness. Yeahh.  \n",
       "484            2        NaN                  Ebay Tights Craigslist Tights  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colbert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>src_type</th>\n",
       "      <th>src_summarized</th>\n",
       "      <th>src_from</th>\n",
       "      <th>src_text</th>\n",
       "      <th>src_root</th>\n",
       "      <th>src_length</th>\n",
       "      <th>com_id</th>\n",
       "      <th>com_summarized</th>\n",
       "      <th>com_text</th>\n",
       "      <th>com_length</th>\n",
       "      <th>com_score</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5lce7x</td>\n",
       "      <td>sub</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>How are you celebrating your news year eve?</td>\n",
       "      <td>celebrate</td>\n",
       "      <td>9</td>\n",
       "      <td>dbumrm1</td>\n",
       "      <td>1</td>\n",
       "      <td>HOORAY!</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you celebrating your news year eve? HO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5lce7x</td>\n",
       "      <td>sub</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>How are you celebrating your news year eve?</td>\n",
       "      <td>celebrate</td>\n",
       "      <td>9</td>\n",
       "      <td>dbun00g</td>\n",
       "      <td>1</td>\n",
       "      <td>Watched the countdown on TV now I'm gonna read...</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you celebrating your news year eve? Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5lce7x</td>\n",
       "      <td>sub</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>How are you celebrating your news year eve?</td>\n",
       "      <td>celebrate</td>\n",
       "      <td>9</td>\n",
       "      <td>dbun0y4</td>\n",
       "      <td>1</td>\n",
       "      <td>Hope that you're having a nice time too.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you celebrating your news year eve? Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5lce7x</td>\n",
       "      <td>sub</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>How are you celebrating your news year eve?</td>\n",
       "      <td>celebrate</td>\n",
       "      <td>9</td>\n",
       "      <td>dbundan</td>\n",
       "      <td>1</td>\n",
       "      <td>Happy new year!</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you celebrating your news year eve? Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5lce7x</td>\n",
       "      <td>sub</td>\n",
       "      <td>0</td>\n",
       "      <td>title</td>\n",
       "      <td>How are you celebrating your news year eve?</td>\n",
       "      <td>celebrate</td>\n",
       "      <td>9</td>\n",
       "      <td>dbuo77q</td>\n",
       "      <td>1</td>\n",
       "      <td>Going on a yacht in marina del ray.</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you celebrating your news year eve? Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>dgfkiax</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Being easily annoyed translates to being mean?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>dghbmdj</td>\n",
       "      <td>0</td>\n",
       "      <td>Uh huh.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Being easily annoyed translates to being mean?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>dcexeyz</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>So how are you?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>dcg7pw5</td>\n",
       "      <td>1</td>\n",
       "      <td>Getting food tomorrow.</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So how are you? Getting food tomorrow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>dcnyjeb</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Oh yeah?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dd2ekl1</td>\n",
       "      <td>0</td>\n",
       "      <td>More shit happened!!!</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oh yeah? More shit happened!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>dcp86v8</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>Why?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dcp8d22</td>\n",
       "      <td>0</td>\n",
       "      <td>I dunno she just is</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why? I dunno she just is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>dd5prlv</td>\n",
       "      <td>com</td>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>What was?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>dd5v6iv</td>\n",
       "      <td>0</td>\n",
       "      <td>the endearment movie 3x</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What was? the endearment movie 3x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src_id src_type  src_summarized src_from  \\\n",
       "5      5lce7x      sub               0    title   \n",
       "6      5lce7x      sub               0    title   \n",
       "7      5lce7x      sub               0    title   \n",
       "8      5lce7x      sub               0    title   \n",
       "9      5lce7x      sub               0    title   \n",
       "...       ...      ...             ...      ...   \n",
       "2098  dgfkiax      com               0  comment   \n",
       "2118  dcexeyz      com               0  comment   \n",
       "2126  dcnyjeb      com               0  comment   \n",
       "2131  dcp86v8      com               0  comment   \n",
       "2161  dd5prlv      com               0  comment   \n",
       "\n",
       "                                            src_text   src_root  src_length  \\\n",
       "5        How are you celebrating your news year eve?  celebrate           9   \n",
       "6        How are you celebrating your news year eve?  celebrate           9   \n",
       "7        How are you celebrating your news year eve?  celebrate           9   \n",
       "8        How are you celebrating your news year eve?  celebrate           9   \n",
       "9        How are you celebrating your news year eve?  celebrate           9   \n",
       "...                                              ...        ...         ...   \n",
       "2098  Being easily annoyed translates to being mean?        NaN           8   \n",
       "2118                                 So how are you?        NaN           5   \n",
       "2126                                        Oh yeah?        NaN           3   \n",
       "2131                                            Why?        NaN           2   \n",
       "2161                                       What was?        NaN           3   \n",
       "\n",
       "       com_id  com_summarized  \\\n",
       "5     dbumrm1               1   \n",
       "6     dbun00g               1   \n",
       "7     dbun0y4               1   \n",
       "8     dbundan               1   \n",
       "9     dbuo77q               1   \n",
       "...       ...             ...   \n",
       "2098  dghbmdj               0   \n",
       "2118  dcg7pw5               1   \n",
       "2126  dd2ekl1               0   \n",
       "2131  dcp8d22               0   \n",
       "2161  dd5v6iv               0   \n",
       "\n",
       "                                               com_text  com_length  \\\n",
       "5                                               HOORAY!           2   \n",
       "6     Watched the countdown on TV now I'm gonna read...          20   \n",
       "7              Hope that you're having a nice time too.          10   \n",
       "8                                       Happy new year!           4   \n",
       "9                   Going on a yacht in marina del ray.           9   \n",
       "...                                                 ...         ...   \n",
       "2098                                            Uh huh.           3   \n",
       "2118                             Getting food tomorrow.           4   \n",
       "2126                              More shit happened!!!           6   \n",
       "2131                                I dunno she just is           5   \n",
       "2161                            the endearment movie 3x           4   \n",
       "\n",
       "      com_score                                           combined  \n",
       "5           NaN  How are you celebrating your news year eve? HO...  \n",
       "6           NaN  How are you celebrating your news year eve? Wa...  \n",
       "7           NaN  How are you celebrating your news year eve? Ho...  \n",
       "8           NaN  How are you celebrating your news year eve? Ha...  \n",
       "9           NaN  How are you celebrating your news year eve? Go...  \n",
       "...         ...                                                ...  \n",
       "2098        NaN  Being easily annoyed translates to being mean?...  \n",
       "2118        NaN             So how are you? Getting food tomorrow.  \n",
       "2126        NaN                     Oh yeah? More shit happened!!!  \n",
       "2131        NaN                           Why? I dunno she just is  \n",
       "2161        NaN                  What was? the endearment movie 3x  \n",
       "\n",
       "[172 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_suffices = [\n",
    "#     '20210501_20211231', '20210101_20210430', '20200101_20201231',\n",
    "#                  '20190101_20191231', '20180101_20181231', '20170101_20171231',\n",
    "                 '20160101_20161231'\n",
    "                ]\n",
    "colbert_df = pd.read_csv('../data/matched_q/casual_conv_20160101_20161231.csv')\n",
    "colbert_df\n",
    "colbert_df['combined'] = colbert_df['src_text']+' '+colbert_df['com_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_suffices = [\n",
    "#     '20210501_20211231', '20210101_20210430', '20200101_20201231',\n",
    "#                  '20190101_20191231', '20180101_20181231', '20170101_20171231',\n",
    "                 '20160101_20161231'\n",
    "                ]\n",
    "for date_suffix in date_suffices:\n",
    "    colbert_df = pd.read_csv('../data/matched_q/casual_conv_{}.csv'.format(date_suffix))\n",
    "    colbert_df['combined'] = colbert_df['src_text']+colbert_df['com_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summarized</th>\n",
       "      <th>text</th>\n",
       "      <th>root</th>\n",
       "      <th>length</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>lmfqjq</td>\n",
       "      <td>0</td>\n",
       "      <td>I can see Mount Fuji outside my window</td>\n",
       "      <td>see</td>\n",
       "      <td>8</td>\n",
       "      <td>0.992325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47982</th>\n",
       "      <td>7or70u</td>\n",
       "      <td>0</td>\n",
       "      <td>Im at home waiting for a robber</td>\n",
       "      <td>be</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>nsp4wk</td>\n",
       "      <td>1</td>\n",
       "      <td>I look back and not one thing went wrong.</td>\n",
       "      <td>look</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34177</th>\n",
       "      <td>a713ot</td>\n",
       "      <td>1</td>\n",
       "      <td>Would love to chat for a distraction!</td>\n",
       "      <td>love</td>\n",
       "      <td>8</td>\n",
       "      <td>0.707652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50478</th>\n",
       "      <td>7b26kv</td>\n",
       "      <td>1</td>\n",
       "      <td>Why even put THAT much effort into a reply?</td>\n",
       "      <td>put</td>\n",
       "      <td>10</td>\n",
       "      <td>0.065793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39368</th>\n",
       "      <td>94rroc</td>\n",
       "      <td>1</td>\n",
       "      <td>I started university last year around October.</td>\n",
       "      <td>start</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51131</th>\n",
       "      <td>77r5f1</td>\n",
       "      <td>0</td>\n",
       "      <td>What’s keeping you up tonight?</td>\n",
       "      <td>keep</td>\n",
       "      <td>7</td>\n",
       "      <td>0.058982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>fxo0ry</td>\n",
       "      <td>0</td>\n",
       "      <td>Trying to stay up cause my cat is sick</td>\n",
       "      <td>try</td>\n",
       "      <td>9</td>\n",
       "      <td>0.981470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25169</th>\n",
       "      <td>d1xlnh</td>\n",
       "      <td>0</td>\n",
       "      <td>So I forgot my cake day</td>\n",
       "      <td>forget</td>\n",
       "      <td>6</td>\n",
       "      <td>0.878770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20567</th>\n",
       "      <td>ekxmb5</td>\n",
       "      <td>1</td>\n",
       "      <td>My ex boyfriend's fuck buddy bought me presents.</td>\n",
       "      <td>buy</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  summarized                                              text  \\\n",
       "5166   lmfqjq           0            I can see Mount Fuji outside my window   \n",
       "47982  7or70u           0                   Im at home waiting for a robber   \n",
       "3447   nsp4wk           1         I look back and not one thing went wrong.   \n",
       "34177  a713ot           1             Would love to chat for a distraction!   \n",
       "50478  7b26kv           1       Why even put THAT much effort into a reply?   \n",
       "39368  94rroc           1    I started university last year around October.   \n",
       "51131  77r5f1           0                    What’s keeping you up tonight?   \n",
       "15174  fxo0ry           0            Trying to stay up cause my cat is sick   \n",
       "25169  d1xlnh           0                           So I forgot my cake day   \n",
       "20567  ekxmb5           1  My ex boyfriend's fuck buddy bought me presents.   \n",
       "\n",
       "         root  length     humor  \n",
       "5166      see       8  0.992325  \n",
       "47982      be       8  0.999689  \n",
       "3447     look      10  0.999849  \n",
       "34177    love       8  0.707652  \n",
       "50478     put      10  0.065793  \n",
       "39368   start       8  0.999950  \n",
       "51131    keep       7  0.058982  \n",
       "15174     try       9  0.981470  \n",
       "25169  forget       6  0.878770  \n",
       "20567     buy      10  0.999948  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path='../data/pickle/all_posts_df.pkl'\n",
    "all_posts_df.to_pickle(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summarized</th>\n",
       "      <th>text</th>\n",
       "      <th>root</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2vbm3</td>\n",
       "      <td>0</td>\n",
       "      <td>Does pressing keyboard keys reflect your perso...</td>\n",
       "      <td>reflect</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2unhy</td>\n",
       "      <td>0</td>\n",
       "      <td>Need some socialization this week ☺️</td>\n",
       "      <td>need</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2tj6o</td>\n",
       "      <td>1</td>\n",
       "      <td>Quarter life crises starts now maybe haha?</td>\n",
       "      <td>start</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2sz0f</td>\n",
       "      <td>1</td>\n",
       "      <td>Do I want to get better?</td>\n",
       "      <td>want</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2sj5n</td>\n",
       "      <td>0</td>\n",
       "      <td>Should I drop them?</td>\n",
       "      <td>drop</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65012</th>\n",
       "      <td>hit:12249_conv:24498_uttr:1</td>\n",
       "      <td>1</td>\n",
       "      <td>I love life these days!</td>\n",
       "      <td>love</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65013</th>\n",
       "      <td>hit:12307_conv:24614_uttr:1</td>\n",
       "      <td>1</td>\n",
       "      <td>I recently tried taking an ice bath</td>\n",
       "      <td>try</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65014</th>\n",
       "      <td>hit:12384_conv:24768_uttr:1</td>\n",
       "      <td>0</td>\n",
       "      <td>I almost got caught stealing, I felt pretty bad</td>\n",
       "      <td>feel</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65015</th>\n",
       "      <td>hit:12398_conv:24797_uttr:1</td>\n",
       "      <td>1</td>\n",
       "      <td>I saw my favourite candy at the store today!</td>\n",
       "      <td>see</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65016</th>\n",
       "      <td>hit:12416_conv:24832_uttr:1</td>\n",
       "      <td>0</td>\n",
       "      <td>I saw a huge cockroach outside my house today!</td>\n",
       "      <td>see</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65017 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  summarized  \\\n",
       "0                           r2vbm3           0   \n",
       "1                           r2unhy           0   \n",
       "2                           r2tj6o           1   \n",
       "3                           r2sz0f           1   \n",
       "4                           r2sj5n           0   \n",
       "...                            ...         ...   \n",
       "65012  hit:12249_conv:24498_uttr:1           1   \n",
       "65013  hit:12307_conv:24614_uttr:1           1   \n",
       "65014  hit:12384_conv:24768_uttr:1           0   \n",
       "65015  hit:12398_conv:24797_uttr:1           1   \n",
       "65016  hit:12416_conv:24832_uttr:1           0   \n",
       "\n",
       "                                                    text     root  length  \n",
       "0      Does pressing keyboard keys reflect your perso...  reflect       8  \n",
       "1                   Need some socialization this week ☺️     need       7  \n",
       "2             Quarter life crises starts now maybe haha?    start       8  \n",
       "3                               Do I want to get better?     want       7  \n",
       "4                                    Should I drop them?     drop       5  \n",
       "...                                                  ...      ...     ...  \n",
       "65012                            I love life these days!     love       6  \n",
       "65013                I recently tried taking an ice bath      try       7  \n",
       "65014    I almost got caught stealing, I felt pretty bad     feel      10  \n",
       "65015       I saw my favourite candy at the store today!      see      10  \n",
       "65016     I saw a huge cockroach outside my house today!      see      10  \n",
       "\n",
       "[65017 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(valid_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
